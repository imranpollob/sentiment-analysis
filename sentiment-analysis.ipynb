{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "sentiment-analysis.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!pip install spacy"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n"
          ]
        }
      ],
      "metadata": {
        "id": "MMqneIlVEuuW",
        "outputId": "a242010f-9ab3-4d88-b236-f09f22415575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 54.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n"
          ]
        }
      ],
      "metadata": {
        "id": "TgwIgomVEwGf",
        "outputId": "5b9d8dfb-9d90-4994-a378-b5d5b8638518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "!pip install matplotlib pandas seaborn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n"
          ]
        }
      ],
      "metadata": {
        "id": "fwIdee-QFhZN",
        "outputId": "df56a98d-f559-4ab2-f7db-9a6e5673b218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "!python -m spacy download en"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ],
      "metadata": {
        "id": "r3yDah_-EuuZ",
        "outputId": "3addfb94-c934-488c-e37a-3f79ece9908d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import spacy \r\n",
        "\r\n",
        "spacy.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "id": "X6pYL1NqEuuZ",
        "outputId": "f9b9254c-4dd7-4dec-ae42-b2ec384bd4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import torch\r\n",
        "import torchtext\r\n",
        "from torchtext import datasets\r\n",
        "\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "outputs": [],
      "metadata": {
        "id": "K4AdSy0BEuub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Twitter Sentiment Analysis Dataset\n",
        "Source: http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/"
      ],
      "metadata": {
        "id": "cuzDe9ZdEuuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "tweets = pd.read_csv('datasets/tweets.csv', error_bad_lines = False)\r\n",
        "\r\n",
        "tweets = tweets.head(50000)\r\n",
        "tweets.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentSource</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>neg</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>neg</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>pos</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>neg</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>neg</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ItemID  ...                                      SentimentText\n",
              "0       1  ...                       is so sad for my APL frie...\n",
              "1       2  ...                     I missed the New Moon trail...\n",
              "2       3  ...                            omg its already 7:30 :O\n",
              "3       4  ...  .. Omgaga. Im sooo  im gunna CRy. I've been at...\n",
              "4       5  ...           i think mi bf is cheating on me!!!   ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {
        "id": "vPNVt94QEuud",
        "outputId": "2e8c9bfc-abff-44a7-cd46-11a427ab2672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataframe consists of 4 columns and we want to use only ‘Sentiment’ and ‘SentimentText’."
      ],
      "metadata": {
        "id": "dOLim1tlEuue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "tweets  = tweets.drop(columns = ['ItemID', 'SentimentSource'], axis = 1)\r\n",
        "\r\n",
        "tweets.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Sentiment                                      SentimentText\n",
              "0       neg                       is so sad for my APL frie...\n",
              "1       neg                     I missed the New Moon trail...\n",
              "2       pos                            omg its already 7:30 :O\n",
              "3       neg  .. Omgaga. Im sooo  im gunna CRy. I've been at...\n",
              "4       neg           i think mi bf is cheating on me!!!   ..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {
        "id": "SAUr4-FNEuue",
        "outputId": "60e9d42f-4b4e-4847-fd68-0289e285b68c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "tweets.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "id": "gwDy4wWnEuuf",
        "outputId": "fa55dd0e-9cc5-4208-d023-c0d21622ac57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "tweets['Sentiment'].unique()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neg', 'pos'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {
        "id": "4ZFT3HezEuuf",
        "outputId": "689b24cb-3617-40fa-af09-cbc4546b4fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "tweets.Sentiment.value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    26921\n",
              "neg    23079\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "id": "IHpH30wKEuug",
        "outputId": "c02d16ac-b072-485a-f7fe-cb40dfb5b406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "fig = plt.figure(figsize=(12, 8))\r\n",
        "\r\n",
        "ax = sns.barplot(x=tweets.Sentiment.unique(), y=tweets.Sentiment.value_counts())\r\n",
        "\r\n",
        "ax.set(xlabel='Labels')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 0, 'Labels')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "T0azD2qAEuug",
        "outputId": "696e3f8e-859e-4d44-f3fd-a52928527940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "train, test = train_test_split(tweets, test_size=0.2, random_state=42)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7YfSUB_fEuuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "train.reset_index(drop=True), test.reset_index(drop=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      Sentiment                                      SentimentText\n",
              " 0           pos  @amyrenea omg so am I lol I fell asleep when i...\n",
              " 1           neg               @Adrienne_Bailon I want a shout out \n",
              " 2           neg  @Anonymousboy03 Plans for school stuff &amp; a...\n",
              " 3           neg  ... has hit a writer's block .. am loosing my ...\n",
              " 4           neg  ... trying to find people I know! I`m bored, i...\n",
              " ...         ...                                                ...\n",
              " 39995       pos   #robotpickuplines are so funny. check them out. \n",
              " 39996       pos  @annyo84 awh thankss.  yeah, i understand what...\n",
              " 39997       pos  @AmbiguityX ohh you're in twin cities?  i luv ...\n",
              " 39998       neg   Dinara lost again in Roland Garros. Why the S...\n",
              " 39999       pos  *yawn* fucking time zones shit. I'm really sic...\n",
              " \n",
              " [40000 rows x 2 columns],\n",
              "      Sentiment                                      SentimentText\n",
              " 0          pos  @aimeesays aww i hope it does fly by because J...\n",
              " 1          neg  #dontyouhate when you JUST painted yur nails a...\n",
              " 2          neg  - @EvertB which one? http://bit.ly/10o8LW, htt...\n",
              " 3          pos  *shriek* Bee almost flew here from window. I'm...\n",
              " 4          pos  @Alyssa_Milano granted if we lose it is to a w...\n",
              " ...        ...                                                ...\n",
              " 9995       neg  @aisforamylynn you're a badass for having a ba...\n",
              " 9996       pos  @acts_rox  I'm not particular about it being f...\n",
              " 9997       pos                     @@j311stp and the same to you!\n",
              " 9998       pos  .@nanere Sheila I heart you!! That &quot;Holly...\n",
              " 9999       neg   not the same without a goodnight....hm. Wish ...\n",
              " \n",
              " [10000 rows x 2 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "id": "-Iz1DiLjEuuh",
        "outputId": "986ebc6f-ea31-4d4c-9c12-a745438c6887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39087</th>\n",
              "      <td>pos</td>\n",
              "      <td>@amyrenea omg so am I lol I fell asleep when i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30893</th>\n",
              "      <td>neg</td>\n",
              "      <td>@Adrienne_Bailon I want a shout out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45278</th>\n",
              "      <td>neg</td>\n",
              "      <td>@Anonymousboy03 Plans for school stuff &amp;amp; a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16398</th>\n",
              "      <td>neg</td>\n",
              "      <td>... has hit a writer's block .. am loosing my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13653</th>\n",
              "      <td>neg</td>\n",
              "      <td>... trying to find people I know! I`m bored, i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Sentiment                                      SentimentText\n",
              "39087       pos  @amyrenea omg so am I lol I fell asleep when i...\n",
              "30893       neg               @Adrienne_Bailon I want a shout out \n",
              "45278       neg  @Anonymousboy03 Plans for school stuff &amp; a...\n",
              "16398       neg  ... has hit a writer's block .. am loosing my ...\n",
              "13653       neg  ... trying to find people I know! I`m bored, i..."
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {
        "id": "7TP0KawZEuuj",
        "outputId": "01d357c1-4a5e-446d-8534-dea00a622df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "train.shape, test.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 2), (10000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "metadata": {
        "id": "0sc2UyMmEuuk",
        "outputId": "e5cfdfee-19ba-4d55-a260-dbac566652ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "train.to_csv('datasets/train_tweets.csv', index=False)\r\n",
        "test.to_csv('datasets/test_tweets.csv', index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OFqyf7R3Euul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "!ls datasets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_tweets.csv  train_tweets.csv  tweets.csv\n"
          ]
        }
      ],
      "metadata": {
        "id": "V-LyYwKEEuul",
        "outputId": "ccba9617-5867-44aa-d0f0-49ca8f50372c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### defining a funtion to clean the tweets by removing non alphanumeric character and links "
      ],
      "metadata": {
        "id": "yDmwKEgMEuul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "def tweet_clean(text):\r\n",
        "    \r\n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) \r\n",
        "    text = re.sub(r'https?:/\\/\\S+', ' ', text) \r\n",
        "    \r\n",
        "    return text.strip()"
      ],
      "outputs": [],
      "metadata": {
        "id": "pNiThwejEuul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  The tweet column (‘SentimentText’) needs processing and tokenization, so that it can be converted into indices."
      ],
      "metadata": {
        "id": "4VusBM3pEuum"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\r\n",
        "\r\n",
        "def tokenizer(s): \r\n",
        "    return [w.text.lower() for w in nlp(tweet_clean(s))]"
      ],
      "outputs": [],
      "metadata": {
        "id": "xxqpkhWoEuum"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "TEXT = torchtext.legacy.data.Field(tokenize = tokenizer)\r\n",
        "\r\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)"
      ],
      "outputs": [],
      "metadata": {
        "id": "cHz-HwsUEuum"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "datafields = [('Sentiment', LABEL), ('SentimentText', TEXT)]"
      ],
      "outputs": [],
      "metadata": {
        "id": "autVKbZkEuun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We create torchtext dataset,TabularDataset which is specially designed to read csv and tsv files and process them. It is a wrapper around pytorch Dataset with additional features. "
      ],
      "metadata": {
        "id": "sAtiHUeLEuun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "trn, tst = torchtext.legacy.data.TabularDataset.splits(path = 'datasets/', \r\n",
        "                                                train = 'train_tweets.csv',\r\n",
        "                                                test = 'test_tweets.csv',    \r\n",
        "                                                format = 'csv',\r\n",
        "                                                skip_header = True,\r\n",
        "                                                fields = datafields)"
      ],
      "outputs": [],
      "metadata": {
        "id": "L3qDQe0XEuun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "print(f'Number of training examples: {len(trn)}')\r\n",
        "print(f'Number of testing examples: {len(tst)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 40000\n",
            "Number of testing examples: 10000\n"
          ]
        }
      ],
      "metadata": {
        "id": "HJ-SVJbqEuun",
        "outputId": "da116c17-d1eb-4ed9-8174-368fc2ae362d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "vars(trn.examples[0])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': 'pos',\n",
              " 'SentimentText': ['amyrenea',\n",
              "  'omg',\n",
              "  'so',\n",
              "  'am',\n",
              "  'i',\n",
              "  'lol',\n",
              "  'i',\n",
              "  'fell',\n",
              "  'asleep',\n",
              "  'when',\n",
              "  'it',\n",
              "  'was',\n",
              "  'on',\n",
              "  'last',\n",
              "  'night',\n",
              "  'so',\n",
              "  'now',\n",
              "  'i',\n",
              "  'get',\n",
              "  'to',\n",
              "  'finish',\n",
              "  'it']}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "metadata": {
        "id": "gKGaaU_KEuuo",
        "outputId": "eeb3ea32-a849-4f9a-e83e-a1db009cfcbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "vars(tst.examples[0])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': 'pos',\n",
              " 'SentimentText': ['aimeesays',\n",
              "  'aww',\n",
              "  'i',\n",
              "  'hope',\n",
              "  'it',\n",
              "  'does',\n",
              "  'fly',\n",
              "  'by',\n",
              "  'because',\n",
              "  'jt',\n",
              "  'episodes',\n",
              "  'are',\n",
              "  'usually',\n",
              "  'really',\n",
              "  'good',\n",
              "  'and',\n",
              "  'it',\n",
              "  's',\n",
              "  'early',\n",
              "  'but',\n",
              "  'so',\n",
              "  'far',\n",
              "  'this',\n",
              "  'ep',\n",
              "  'hassn',\n",
              "  't',\n",
              "  'disappointed']}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "metadata": {
        "id": "yXnK8xi5Euuo",
        "outputId": "34ba531d-4076-49cd-adc4-f3c307176411",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load pretrained word vectors and build vocabulary\n",
        "Now, instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors. We get these vectors simply by specifying which vectors we want and passing it as an argument to build_vocab. TorchText handles downloading the vectors and associating them with the correct words in our vocabulary."
      ],
      "metadata": {
        "id": "wD0XOH8hEuup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "TEXT.build_vocab(trn, max_size=25000,\r\n",
        "                 vectors=\"glove.6B.100d\",\r\n",
        "                 unk_init=torch.Tensor.normal_)\r\n",
        "\r\n",
        "LABEL.build_vocab(trn)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:17<00:00, 22717.71it/s]\n"
          ]
        }
      ],
      "metadata": {
        "id": "7PS1CJJSEuup",
        "outputId": "35931e74-a1f5-4fc2-9c05-782f97015d39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "print(TEXT.vocab.freqs.most_common(50))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('i', 25644), ('the', 12219), ('to', 12111), ('you', 10723), ('a', 9197), ('it', 8440), ('and', 6889), ('my', 6208), ('quot', 5582), ('s', 5564), ('that', 5306), ('is', 5203), ('for', 4971), ('in', 4852), ('t', 4844), ('m', 4683), ('me', 4588), ('of', 4331), ('on', 3918), ('have', 3752), ('so', 3612), ('but', 3506), ('be', 2932), ('not', 2887), ('was', 2775), ('just', 2724), ('can', 2523), ('do', 2418), ('are', 2351), ('your', 2320), ('with', 2269), ('good', 2203), ('like', 2173), ('at', 2131), ('no', 2119), ('this', 2093), ('all', 2069), ('up', 2066), ('now', 2063), ('get', 2044), ('we', 1988), ('u', 1890), ('love', 1885), ('lol', 1864), ('too', 1826), ('what', 1760), ('out', 1742), ('know', 1664), ('nt', 1608), ('amp', 1539)]\n"
          ]
        }
      ],
      "metadata": {
        "id": "smBrx3zwEuup",
        "outputId": "3a558882-9c73-487a-8821-db22a2bee1af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'i', 'the', 'to', 'you', 'a', 'it', 'and', 'my']\n"
          ]
        }
      ],
      "metadata": {
        "id": "82w7ilOFEuuq",
        "outputId": "f8d8add4-98e2-4f41-e971-3f1077500a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'pos': 0, 'neg': 1})\n"
          ]
        }
      ],
      "metadata": {
        "id": "7P5iGB3wEuur",
        "outputId": "66d4ce47-c698-4dcd-d1bd-c0ab422ea2ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the data in batches\n",
        "For data with variable length sentences torchtext provides BucketIterator() dataloader which is wrapper around pytorch Dataloader. "
      ],
      "metadata": {
        "id": "_V-kplD1Euur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "train_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\r\n",
        "                                (trn, tst),\r\n",
        "                                batch_size = 64,\r\n",
        "                                sort_key=lambda x: len(x.SentimentText),\r\n",
        "                                sort_within_batch=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GTskLWvQEuus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We'll be using a different RNN architecture called a Long Short-Term Memory (LSTM).\n",
        "\n",
        "<b>torch.nn.embedding</b> -A simple lookup table that stores embeddings of a fixed dictionary and size.This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "\n",
        "\n",
        "<b>LSTM</b> - Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n",
        "\n",
        "<b>bidirectional</b> - an RNN processing the words in the sentence from the first to the last (a forward RNN), we have a second RNN processing the words in the sentence from the last to the first (a backward RNN). At time step $t$, the forward RNN is processing word $x_t$, and the backward RNN is processing word $x_{T-t+1}$.\n",
        "\n",
        "\n",
        "<b>Dropout</b> - it works by randomly dropping out (setting to 0) neurons in a layer during a forward pass. The probability that each neuron is dropped out is set by a hyperparameter and each neuron with dropout applied is considered indepenently.This helps in regularization.\n"
      ],
      "metadata": {
        "id": "8UXp_kAPEuus"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "import torch.nn as nn\r\n",
        "\r\n",
        "class RNN(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \r\n",
        "                 output_dim, n_layers, bidirectional, dropout):\r\n",
        "        \r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \r\n",
        "                           bidirectional = bidirectional, dropout=dropout)\r\n",
        "        \r\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "\r\n",
        "        \r\n",
        "    def forward(self, text):\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(text))\r\n",
        "        \r\n",
        "        output, hidden = self.rnn(embedded)\r\n",
        "        \r\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\r\n",
        "       \r\n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "outputs": [],
      "metadata": {
        "id": "PJb9lCLHEuut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure the pre-trained vectors can be loaded into the model, the EMBEDDING_DIM must be equal to that of the pre-trained GloVe vectors loaded earlier.\n",
        "\n",
        "We get our pad token index from the vocabulary, getting the actual string representing the pad token from the field's pad_token attribute, which is pad by default."
      ],
      "metadata": {
        "id": "Ec5RMiKDEuut"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "input_dim = len(TEXT.vocab)\r\n",
        "\r\n",
        "embedding_dim = 100\r\n",
        "\r\n",
        "hidden_dim = 20\r\n",
        "output_dim = 1\r\n",
        "\r\n",
        "n_layers = 2\r\n",
        "bidirectional = True\r\n",
        "\r\n",
        "dropout = 0.5"
      ],
      "outputs": [],
      "metadata": {
        "id": "roazRN86Euuu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "model = RNN(input_dim, \r\n",
        "            embedding_dim, \r\n",
        "            hidden_dim, \r\n",
        "            output_dim, \r\n",
        "            n_layers, \r\n",
        "            bidirectional, \r\n",
        "            dropout)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DINdPVx4Euuu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(25002, 100)\n",
              "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "metadata": {
        "id": "qxXlgAlZEuuu",
        "outputId": "aab94c80-684b-4581-c87e-d98ba3c4f17b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retrieve the embeddings from the field's vocab, and check they're the correct size, [vocab size, embedding dim]"
      ],
      "metadata": {
        "id": "WjQiDfe7Euuu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\r\n",
        "\r\n",
        "print(pretrained_embeddings.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 100])\n"
          ]
        }
      ],
      "metadata": {
        "id": "KJ_nCtVyEuuv",
        "outputId": "0e0d5de3-6ee5-40ff-ed66-ba612aba3b77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings."
      ],
      "metadata": {
        "id": "1k0Vb-CrEuuv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.4996,  1.4951, -0.2231,  ..., -0.5533,  0.7685,  2.0863],\n",
              "        [-0.0698, -0.0213, -0.5367,  ...,  1.1086, -0.0526, -0.4446],\n",
              "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
              "        ...,\n",
              "        [ 1.4102, -0.4384, -0.5643,  ..., -0.4680,  0.5986,  1.1303],\n",
              "        [ 0.1329, -1.8298,  0.0212,  ...,  1.1834, -0.9601, -1.0668],\n",
              "        [-0.4119, -1.1630, -0.4201,  ..., -1.8282,  0.1736,  0.9117]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "metadata": {
        "id": "kERTYyYWEuuw",
        "outputId": "764fe2c8-2b07-4018-a2fb-3daac687eec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our < unk > and < pad > token aren't in the pre-trained vocabulary they have been initialized using unk_init (an $\\mathcal{N}(0,1)$ distribution) when building our vocab. It is preferable to initialize them both to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment."
      ],
      "metadata": {
        "id": "MoL-uU8bEuuw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\r\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\r\n",
        "\r\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\r\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\r\n",
        "\r\n",
        "print(model.embedding.weight.data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
            "        ...,\n",
            "        [ 1.4102, -0.4384, -0.5643,  ..., -0.4680,  0.5986,  1.1303],\n",
            "        [ 0.1329, -1.8298,  0.0212,  ...,  1.1834, -0.9601, -1.0668],\n",
            "        [-0.4119, -1.1630, -0.4201,  ..., -1.8282,  0.1736,  0.9117]])\n"
          ]
        }
      ],
      "metadata": {
        "id": "Af79eWhAEuuw",
        "outputId": "b245ecc9-a6cd-4714-fc99-492e9b97fbd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the Model\n",
        "\n",
        "We use Adam optimizer and loss function is BCEWithLogitLoss "
      ],
      "metadata": {
        "id": "w0RIAOn7Euux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "\r\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "outputs": [],
      "metadata": {
        "id": "uoYqPdvtEuux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We define a function for training our model\n",
        "as we are now using dropout, we must remember to use model.train() to ensure the dropout is \"turned on\" while training."
      ],
      "metadata": {
        "id": "FHsyPolOEuux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    for batch in iterator:\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        predictions = model(batch.SentimentText).squeeze(1)\r\n",
        "        \r\n",
        "        loss = criterion(predictions, batch.Sentiment)\r\n",
        "        \r\n",
        "        rounded_preds = torch.round(torch.sigmoid(predictions))\r\n",
        "        correct = (rounded_preds == batch.Sentiment).float() \r\n",
        "        \r\n",
        "        acc = correct.sum() / len(correct)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FQhc7eNfEuuy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "num_epochs = 10\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "     \r\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "    \r\n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch: 01 | Train Loss: 0.639 | Train Acc: 62.44% |\n",
            "| Epoch: 02 | Train Loss: 0.539 | Train Acc: 73.24% |\n",
            "| Epoch: 03 | Train Loss: 0.494 | Train Acc: 76.41% |\n",
            "| Epoch: 04 | Train Loss: 0.467 | Train Acc: 78.23% |\n",
            "| Epoch: 05 | Train Loss: 0.442 | Train Acc: 79.68% |\n",
            "| Epoch: 06 | Train Loss: 0.425 | Train Acc: 80.75% |\n",
            "| Epoch: 07 | Train Loss: 0.405 | Train Acc: 81.95% |\n",
            "| Epoch: 08 | Train Loss: 0.388 | Train Acc: 82.94% |\n",
            "| Epoch: 09 | Train Loss: 0.373 | Train Acc: 83.73% |\n",
            "| Epoch: 10 | Train Loss: 0.360 | Train Acc: 84.50% |\n"
          ]
        }
      ],
      "metadata": {
        "id": "yO76NptNEuuy",
        "outputId": "915462e6-6b5b-4782-fbe4-1b0cfc5b2035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model"
      ],
      "metadata": {
        "id": "YKhe-83REuuy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "epoch_loss = 0\r\n",
        "epoch_acc = 0\r\n",
        "\r\n",
        "model.eval()\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "\r\n",
        "    for batch in test_iterator:\r\n",
        "\r\n",
        "        predictions = model(batch.SentimentText).squeeze(1)\r\n",
        "\r\n",
        "        loss = criterion(predictions, batch.Sentiment)\r\n",
        "\r\n",
        "        rounded_preds = torch.round(torch.sigmoid(predictions))\r\n",
        "        correct = (rounded_preds == batch.Sentiment).float() \r\n",
        "        \r\n",
        "        acc = correct.sum()/len(correct)\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc.item()\r\n",
        "\r\n",
        "\r\n",
        "test_loss = epoch_loss / len(test_iterator)\r\n",
        "test_acc = epoch_acc / len(test_iterator)\r\n",
        "\r\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.505 | Test Acc: 76.76%\n"
          ]
        }
      ],
      "metadata": {
        "id": "3TQEpbABEuuz",
        "outputId": "fbe96f8c-78aa-49fd-bbe2-6dba053c56ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User Input\n",
        "We can now use our model to predict the sentiment of any sentence we give it.As it has been trained on tweets, the sentences provided should in a positive or a negative context.\n",
        "\n",
        "We are expecting tweets with a negative sentiment to return a value close to 1 and positive tweets to return a value close to 0\n"
      ],
      "metadata": {
        "id": "6uuwTHdBEuuz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "sentence = 'I hate that show' \r\n",
        "\r\n",
        "#Run again for \"That movie was really nice\"\r\n",
        "#Run again for \"I hate that show but recently it has been quite good\"\r\n",
        "#Run again for \"That movie was decent but kind of fizzled out towards the end\""
      ],
      "outputs": [],
      "metadata": {
        "id": "3dRJZXfoEuuz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "tokenized = [tok.text for tok in nlp.tokenizer(sentence)]"
      ],
      "outputs": [],
      "metadata": {
        "id": "bSk8Og2oEuu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "indexed = [TEXT.vocab.stoi[t] for t in tokenized]"
      ],
      "outputs": [],
      "metadata": {
        "id": "tXP-s4SMEuu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "tensor = torch.LongTensor(indexed)"
      ],
      "outputs": [],
      "metadata": {
        "id": "H6I-qNvtEuu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "tensor = tensor.unsqueeze(1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "cICWReMPEuu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "source": [
        "prediction = torch.sigmoid(model(tensor))"
      ],
      "outputs": [],
      "metadata": {
        "id": "v47eySi1Euu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "source": [
        "prediction.item()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9009069800376892"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "metadata": {
        "id": "JavLZA4tEuu0",
        "outputId": "6c5ca539-3bfb-4bf2-b1f6-a92fe9c0797b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ]
}